import os
import hmac
import hashlib
from time import sleep
import openai
from github import Github
import re


# def preprocess_changes(changes_str):
# return re.sub(r'@@.*?@@', '', changes_str)  # 移除 @@ ... @@ 行
# lines = changes_str.split('\n')
# processed_lines = []
# for line in lines:
#     if line.startswith('+'):
#         processed_lines.append(f'(+) {line[1:]}')
#     elif line.startswith('-'):
#         processed_lines.append(f'(-) {line[1:]}')
#     else:
#         processed_lines.append(line)
# return '\n'.join(processed_lines)

# Set up OpenAI API client
openai.api_key = os.environ.get("OPENAI_API_KEY")
# Set up GitHub API client
gh = Github(os.environ.get("GITHUB_TOKEN"))

# Get the code changes from the PR
# gh_repo = gh.get_repo("pytorch/pytorch")
# gh_pr = gh_repo.get_pull(98916)
gh_repo = gh.get_repo("OpenRHINO/RHINO-Operator")
gh_pr = gh_repo.get_pull(38)
# gh_repo = gh.get_repo("OpenRHINO/RHINO-CLI")
# #gh_pr = gh_repo.get_pull(58) #这里有很多exit(0)或exit(1)改为return err, 但是gpt-3.5-turbo生成的review中经常会弄反
# gh_pr = gh_repo.get_pull(46)
code_changes = gh_pr.get_files()

# gh_repo = gh.get_repo("kubernetes/kubernetes")
# gh_pr = gh_repo.get_pull(117245)
# code_changes = gh_pr.get_files()

# Concatenate the changes into a single string
changes_str = "Title: " + gh_pr.title + "\n"
if gh_pr.body is not None:
    changes_str += "Body: " + gh_pr.body + "\n"
for change in code_changes:
    changes_str += f"File: {change.filename}\nPatch:\n{change.patch}\n\n"
# changes_str = preprocess_changes(changes_str)
print(changes_str)

# Call GPT to get the review result
messages = [
    {
        "role": "system",
        "content": "As an AI assistant with programming expertise, you are a meticulous code reviewer."},
    {"role": "user",
        "content": f"Review the following pull request:\n{changes_str}\n\nThe '+' means the line is added, and the '-' means the line is removed. Please provide a review result for the PR."}
]
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=messages,
    max_tokens=600,
    temperature=0.5,
    n=5
)

# Create a list of reviews from the response by "gp-3.5-turbo"
reviews = [
    f"Review {i+1}:\n{response.choices[i]['message']['content'].strip()}\n" for i in range(len(response.choices))]

# Combine the reviews into a single string
reviews_str = "\n".join(reviews)
print(reviews_str)
# Call GPT to generate the summary of the reviews
summary_messages = [
    {"role": "system",
     "content": f"Here are some review results for reference:\n{reviews_str}"},
    {"role": "user",
     "content": "You are a software developing expert. Please summarize the review results. Ensure that the output follows the template:'\n\n**[Changes]**\n\n**[Suggestions]**\n\n**[Conclusion]**\n\n**[Action]**\n\n**[Other]**\n\n'."}
]

summary_response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=summary_messages,
    max_tokens=600,
    temperature=0.5,
    n=1
)

final_review = f"""**[AI Review]** This comment is generated by an AI model (gpt-3.5-turbo).\n\n{summary_response.choices[0]['message']['content'].strip()}\n
**[Note]** 
The above AI review results are for reference only, please rely on human expert review results for the final conclusion.
Usually, AI is better at enhancing the quality of code snippets. However, it's essential for human experts to pay close attention to whether the modifications meet the overall requirements. Providing detailed information in the PR description helps the AI generate more specific and useful review results.\n\n"""

# Print the final review result
print(final_review)

translate_messages = [
    {"role": "user",
     "content": f"将下面内容翻译为中文{final_review}"
     }
]
translated_response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=translate_messages,
    max_tokens=2000,
    temperature=0.8,
    n=1
)
print(translated_response.choices[0]['message']['content'].strip())

# code_modification_messages = [
#     {"role": "system",
#      "content": f"Here are some review results:\n{summary_response.choices[0]['message']['content'].strip()}"},
#     {"role": "user",
#         "content": f"Please follow the provided suggestions to modify the following code. Update the parts you can, and if you're unsure how to make a change, feel free to skip it. Output the modified code snippet directly, without using the code changes format. There is no need to include parts that haven't been modified.\n{changes_str}"
#     }
# ]
# code_modification_response = openai.ChatCompletion.create(
#     model="gpt-3.5-turbo",
#     messages=code_modification_messages,
#     max_tokens=2000,
#     temperature=0.5,
#     n=1
# )
# print(code_modification_response.choices[0]['message']['content'].strip())
